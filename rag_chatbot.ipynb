{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFOkHe4hY2kY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 0: Download and Prepare Knowledge Base ---\n",
        "!pip install -q PyPDF2 sentence-transformers faiss-cpu transformers gradio\n",
        "\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# üîπ Replace this link with the *raw* link to your PDF in GitHub\n",
        "pdf_url = \"https://raw.githubusercontent.com/<your-username>/<your-repo-name>/main/Human-Resource-HR-Policy-.pdf\"\n",
        "pdf_path = \"Human-Resource-HR-Policy-.pdf\"\n",
        "\n",
        "# Download the PDF from GitHub\n",
        "os.system(f\"wget -O {pdf_path} {pdf_url}\")\n",
        "\n",
        "# Convert PDF to text\n",
        "reader = PdfReader(pdf_path)\n",
        "knowledge_text = \"\"\n",
        "for page in reader.pages:\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        knowledge_text += text + \"\\n\"\n",
        "\n",
        "# Save as a text file for reference\n",
        "with open(\"my_knowledge.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(knowledge_text)\n",
        "\n",
        "print(\"‚úÖ PDF downloaded and converted to text successfully!\")\n",
        "\n",
        "# --- Step 1: Load the knowledge text ---\n",
        "with open(\"my_knowledge.txt\", \"r\") as f:\n",
        "    knowledge_text = f.read()\n",
        "\n",
        "# --- Step 2: Chunking ---\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len\n",
        ")\n",
        "chunks = text_splitter.split_text(knowledge_text)\n",
        "print(f\"‚úÖ We have {len(chunks)} chunks.\")\n",
        "\n",
        "# --- Step 3: Embeddings ---\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "chunk_embeddings = model.encode(chunks)\n",
        "\n",
        "# --- Step 4: Vector Store with FAISS ---\n",
        "import faiss, numpy as np\n",
        "d = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(np.array(chunk_embeddings).astype('float32'))\n",
        "print(f\"‚úÖ FAISS index created with {index.ntotal} vectors.\")\n",
        "\n",
        "# --- Step 5: Load Generator Model ---\n",
        "from transformers import pipeline\n",
        "generator = pipeline('text2text-generation', model='google/flan-t5-small')\n",
        "\n",
        "# --- Step 6: Initialize Conversation History ---\n",
        "conversation_history = []\n",
        "\n",
        "# --- Step 7: Define RAG Function with Memory + Citation ---\n",
        "def answer_question(query):\n",
        "    # Embed query\n",
        "    query_embedding = model.encode([query]).astype('float32')\n",
        "    k = 2\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
        "    context = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "    # Include last 3 exchanges in context\n",
        "    past_context = \"\\n\\n\".join(\n",
        "        [f\"User: {h['query']}\\nBot: {h['answer']}\" for h in conversation_history[-3:]]\n",
        "    )\n",
        "\n",
        "    prompt_template = f\"\"\"\n",
        "    Use only the provided context to answer the user's question.\n",
        "    If the answer isn't found, say \"I don't have that information.\"\n",
        "\n",
        "    Previous conversation:\n",
        "    {past_context}\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate answer\n",
        "    response = generator(prompt_template, max_length=150)[0]['generated_text']\n",
        "\n",
        "    # Save conversation\n",
        "    conversation_history.append({\"query\": query, \"answer\": response})\n",
        "\n",
        "    # Add citation\n",
        "    final_answer = f\"{response}\\n\\n(Source: Human-Resource-HR-Policy-.pdf)\"\n",
        "    return final_answer\n",
        "\n",
        "# --- Step 8: Test it ---\n",
        "query_1 = \"What is the WFH policy?\"\n",
        "print(f\"Q: {query_1}\")\n",
        "print(answer_question(query_1))\n",
        "\n",
        "# --- Step 9: Gradio Interface ---\n",
        "import gradio as gr\n",
        "\n",
        "def chatbot_interface(query):\n",
        "    answer = answer_question(query)\n",
        "    if \"(Source:\" in answer:\n",
        "        main_answer, source = answer.split(\"(Source:\", 1)\n",
        "        source = \"(Source:\" + source\n",
        "    else:\n",
        "        main_answer, source = answer, \"No source found\"\n",
        "    return main_answer.strip(), source.strip()\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_interface,\n",
        "    inputs=gr.Textbox(label=\"Ask about company policy\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Chatbot Answer\"),\n",
        "        gr.Textbox(label=\"Source\")\n",
        "    ],\n",
        "    title=\"Company Policy Chatbot (RAG with Memory + Citation)\",\n",
        "    description=\"Retrieves answers from company policy PDF and cites sources. Remembers recent conversation.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "UfgHRZaDb6Yp",
        "outputId": "7ef26534-a6bf-427c-898f-3776c77c60a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Human-Resource-HR-Policy-.pdf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1740328499.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Convert PDF to text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mknowledge_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PyPDF2/_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    315\u001b[0m             )\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Human-Resource-HR-Policy-.pdf'"
          ]
        }
      ]
    }
  ]
}